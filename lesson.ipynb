{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
    "from azure.cognitiveservices.vision.computervision.models import VisualFeatureTypes\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "\n",
    "from array import array\n",
    "import os\n",
    "from PIL import Image\n",
    "import sys\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./config/secret.json') as f:\n",
    "    secret = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY = secret['KEY']\n",
    "ENDPOINT = secret['ENDPOINT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "computervision_client = ComputerVisionClient(ENDPOINT, CognitiveServicesCredentials(KEY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_image_url = \"https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/ComputerVision/Images/landmark.jpg\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 画像タグの検出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Tag an image - remote =====\n",
      "Tags in the remote image: \n",
      "'屋外' with confidence 99.00%\n",
      "'建物' with confidence 98.81%\n",
      "'空' with confidence 98.21%\n",
      "'スタジアム' with confidence 98.17%\n",
      "'古代ローマ' with confidence 96.16%\n",
      "'遺跡' with confidence 95.04%\n",
      "'アンフィテアトルム' with confidence 93.99%\n",
      "'ローマ建築' with confidence 92.65%\n",
      "'史跡' with confidence 89.55%\n",
      "'古代史' with confidence 89.54%\n",
      "'歴史' with confidence 86.72%\n",
      "'遺跡' with confidence 84.41%\n",
      "'旅行' with confidence 65.85%\n",
      "'大きい' with confidence 61.02%\n",
      "'都市' with confidence 56.57%\n",
      "\n",
      "End of Computer Vision quickstart.\n"
     ]
    }
   ],
   "source": [
    "print(\"===== Tag an image - remote =====\")\n",
    "# Call API with remote image\n",
    "tags_result_remote = computervision_client.tag_image(remote_image_url, language='ja')\n",
    "\n",
    "# Print results with confidence score\n",
    "print(\"Tags in the remote image: \")\n",
    "if (len(tags_result_remote.tags) == 0):\n",
    "    print(\"No tags detected.\")\n",
    "else:\n",
    "    for tag in tags_result_remote.tags:\n",
    "        print(\"'{}' with confidence {:.2f}%\".format(tag.name, tag.confidence * 100))\n",
    "print()\n",
    "'''\n",
    "END - Tag an Image - remote\n",
    "'''\n",
    "print(\"End of Computer Vision quickstart.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 画像の説明の取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Describe an image - remote =====\n",
      "Description of remote image: \n",
      "'城のような建物、背景はコロッセオ' with confidence 61.39%\n",
      "\n",
      "End of Computer Vision quickstart.\n"
     ]
    }
   ],
   "source": [
    "print(\"===== Describe an image - remote =====\")\n",
    "# Call API with remote image\n",
    "description_results = computervision_client.describe_image(remote_image_url, language='ja')\n",
    "\n",
    "# Print results with confidence score\n",
    "print(\"Description of remote image: \")\n",
    "if (len(description_results.captions) == 0):\n",
    "    print(\"No description detected.\")\n",
    "else:\n",
    "    for caption in description_results.captions:\n",
    "        print(\"'{}' with confidence {:.2f}%\".format(caption.text, caption.confidence * 100))\n",
    "print()\n",
    "'''\n",
    "END - Tag an Image - remote\n",
    "'''\n",
    "print(\"End of Computer Vision quickstart.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 画像カテゴリの取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Analyze an image - remote =====\n",
      "Categories from remote image: \n",
      "'建物_' with confidence 31.64%\n",
      "'その他_' with confidence 0.39%\n",
      "'屋外_' with confidence 3.91%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"===== Analyze an image - remote =====\")\n",
    "# Select the visual feature(s) you want.\n",
    "remote_image_features = [VisualFeatureTypes.categories,VisualFeatureTypes.brands,VisualFeatureTypes.adult,VisualFeatureTypes.color,VisualFeatureTypes.description,VisualFeatureTypes.faces,VisualFeatureTypes.image_type,VisualFeatureTypes.objects,VisualFeatureTypes.tags]\n",
    "# Call API with URL and features\n",
    "results_remote = computervision_client.analyze_image(remote_image_url , remote_image_features, language='ja')\n",
    "\n",
    "# Print results with confidence score\n",
    "print(\"Categories from remote image: \")\n",
    "if (len(results_remote.categories) == 0):\n",
    "    print(\"No categories detected.\")\n",
    "else:\n",
    "    for category in results_remote.categories:\n",
    "        print(\"'{}' with confidence {:.2f}%\".format(category.name, category.score * 100))\n",
    "print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 物体検出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Analyze an image - remote =====\n",
      "Detecting objects in remote image:\n",
      "object at location 213, 365, 85, 208\n",
      "object at location 218, 402, 179, 384\n",
      "object at location 238, 417, 298, 416\n",
      "object at location 116, 419, 60, 386\n"
     ]
    }
   ],
   "source": [
    "remote_image_url3 = \"https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/ComputerVision/Images/objects.jpg\"\n",
    "\n",
    "print(\"===== Analyze an image - remote =====\")\n",
    "# Select the visual feature(s) you want.\n",
    "remote_image_features = [VisualFeatureTypes.categories,VisualFeatureTypes.brands,VisualFeatureTypes.adult,VisualFeatureTypes.color,VisualFeatureTypes.description,VisualFeatureTypes.faces,VisualFeatureTypes.image_type,VisualFeatureTypes.objects,VisualFeatureTypes.tags]\n",
    "\n",
    "# Call API with URL and features\n",
    "results_remote = computervision_client.analyze_image(remote_image_url3 , remote_image_features, language='ja')\n",
    "\n",
    "# Detect objects\n",
    "# Print detected objects results with bounding boxes\n",
    "print(\"Detecting objects in remote image:\")\n",
    "if len(results_remote.objects) == 0:\n",
    "    print(\"No objects detected.\")\n",
    "else:\n",
    "    for object in results_remote.objects:\n",
    "        print(\"object at location {}, {}, {}, {}\".format( \\\n",
    "        object.rectangle.x, object.rectangle.x + object.rectangle.w, \\\n",
    "        object.rectangle.y, object.rectangle.y + object.rectangle.h))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ローカルファイルに対応"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 物体検出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Analyze an image - local =====\n",
      "Detecting objects in local image:\n",
      "object at location 879, 1201, 262, 773\n",
      "object at location 426, 1085, 835, 1271\n"
     ]
    }
   ],
   "source": [
    "local_image_path = './images/sample01.jpg'\n",
    "local_image = open(local_image_path, 'rb')\n",
    "\n",
    "print(\"===== Analyze an image - local =====\")\n",
    "# Select the visual feature(s) you want.\n",
    "remote_image_features = [VisualFeatureTypes.categories,VisualFeatureTypes.brands,VisualFeatureTypes.adult,VisualFeatureTypes.color,VisualFeatureTypes.description,VisualFeatureTypes.faces,VisualFeatureTypes.image_type,VisualFeatureTypes.objects,VisualFeatureTypes.tags]\n",
    "\n",
    "# Call API with URL and features\n",
    "results_local = computervision_client.analyze_image_in_stream(local_image , remote_image_features, language='ja')\n",
    "\n",
    "# Detect objects\n",
    "# Print detected objects results with bounding boxes\n",
    "print(\"Detecting objects in local image:\")\n",
    "if len(results_local.objects) == 0:\n",
    "    print(\"No objects detected.\")\n",
    "else:\n",
    "    for object in results_local.objects:\n",
    "        print(\"object at location {}, {}, {}, {}\".format( \\\n",
    "        object.rectangle.x, object.rectangle.x + object.rectangle.w, \\\n",
    "        object.rectangle.y, object.rectangle.y + object.rectangle.h))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 画像タグの検出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['食器',\n",
       " '食品',\n",
       " 'オーブンで焼かれた食品',\n",
       " 'プレート',\n",
       " '飲料',\n",
       " 'コーヒー カップ',\n",
       " '食器類',\n",
       " 'ソーサー',\n",
       " 'スナック',\n",
       " 'サーブウェア',\n",
       " '食事',\n",
       " 'マグカップ',\n",
       " 'お茶',\n",
       " 'ファスト フード',\n",
       " '朝食',\n",
       " 'フォーク',\n",
       " '食器',\n",
       " '料理',\n",
       " 'ブランチ (食事)',\n",
       " '大皿',\n",
       " 'デザート',\n",
       " 'カップ',\n",
       " 'コーヒー',\n",
       " '屋内',\n",
       " '座っている',\n",
       " 'テーブル']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_image_path = './images/sample01.jpg'\n",
    "# local_image = open(local_image_path, 'rb')\n",
    "\n",
    "with open(local_image_path, 'rb') as local_image:\n",
    "    tags_result_local = computervision_client.tag_image_in_stream(local_image, language='ja')\n",
    "    tags = []\n",
    "    for tag in tags_result_local.tags:\n",
    "        tags.append(tag.name)\n",
    "\n",
    "    local_image.close()\n",
    "\n",
    "tags"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_image_path = './images/sample01.jpg'\n",
    "\n",
    "def read_local_image(filepath: str) -> object:\n",
    "    with open(filepath, 'rb') as local_image:\n",
    "        yield local_image\n",
    "\n",
    "def analyze_local_image(local_image: object, language: str='en') -> object:\n",
    "    # remote_image_features = [VisualFeatureTypes.categories,VisualFeatureTypes.brands,VisualFeatureTypes.adult,VisualFeatureTypes.color,VisualFeatureTypes.description,VisualFeatureTypes.faces,VisualFeatureTypes.image_type,VisualFeatureTypes.objects,VisualFeatureTypes.tags]\n",
    "    remote_image_features = [VisualFeatureTypes.categories, VisualFeatureTypes.objects, VisualFeatureTypes.tags]\n",
    "    results_local = computervision_client.analyze_image_in_stream(local_image , remote_image_features, language=language)\n",
    "    return results_local\n",
    "\n",
    "def get_local_tags(results: object):\n",
    "    tags = []\n",
    "    for tag in results.tags:\n",
    "        tags.append(tag.name)\n",
    "    \n",
    "    return tags\n",
    "\n",
    "def get_detect_objects(results: object):\n",
    "    return results.objects\n",
    "\n",
    "    # for object in results.objects:\n",
    "    #     print(\"object at location {}, {}, {}, {}\".format( \\\n",
    "    #     object.rectangle.x, object.rectangle.x + object.rectangle.w, \\\n",
    "    #     object.rectangle.y, object.rectangle.y + object.rectangle.h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['食器', '食品', 'オーブンで焼かれた食品', 'プレート', '飲料', 'コーヒー カップ', '食器類', 'ソーサー', 'スナック', 'サーブウェア', '食事', 'マグカップ', 'お茶', 'ファスト フード', '朝食', 'フォーク', '料理', 'ブランチ (食事)', '大皿', 'デザート', 'カップ', 'コーヒー', '屋内', '座っている', 'テーブル']\n",
      "object at location 1211, 1379, 227, 539\n",
      "cup\n",
      "object at location 871, 1206, 257, 779\n",
      "cup\n",
      "object at location 423, 1086, 829, 1256\n",
      "Food\n",
      "object at location 1258, 1746, 752, 1292\n",
      "Fork\n",
      "object at location 30, 1615, 176, 1434\n",
      "dining table\n"
     ]
    }
   ],
   "source": [
    "for local_image in read_local_image(local_image_path):\n",
    "    results = analyze_local_image(local_image, language='ja')\n",
    "    tags = get_local_tags(results)\n",
    "    print(tags)\n",
    "    objects = get_detect_objects(results)\n",
    "    for object in objects:\n",
    "        print(\"object at location {}, {}, {}, {}\".format( \\\n",
    "        object.rectangle.x, object.rectangle.x + object.rectangle.w, \\\n",
    "        object.rectangle.y, object.rectangle.y + object.rectangle.h))\n",
    "        print(object.object_property)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
